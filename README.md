# Smart Assistant for Research Summarization

A smart assistant designed to help researchers upload documents, get concise summaries, ask intelligent questions, and test their understanding via challenge-based questionsâ€”all powered by Google Gemini and FAISS.

---

# ğŸ“ Project Structure: Smart Assistant for Research Summarization

smart-assistant/
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ app/
â”‚ â”‚ â”œâ”€â”€ init.py
â”‚ â”‚ â”œâ”€â”€ main.py # FastAPI app with API endpoints
â”‚ â”‚ â”œâ”€â”€ document_processor.py # Handles PDF/TXT extraction and summarization
â”‚ â”‚ â”œâ”€â”€ question_answerer.py # Handles question answering and justification
â”‚ â”‚ â”œâ”€â”€ question_generator.py # Generates logic-based questions
â”‚ â”‚ â”œâ”€â”€ answer_evaluator.py # Evaluates user answers in Challenge Me mode
â”‚ â”‚ â””â”€â”€ models/
â”‚ â”‚ â”œâ”€â”€ init.py
â”‚ â”‚ â”œâ”€â”€ document.py # Data models for documents and responses
â”‚ â”‚ â””â”€â”€ context.py # Manages conversation context (for memory)
â”‚ â”œâ”€â”€ requirements.txt # Python dependencies
â”‚ â””â”€â”€ .env # Environment variables (e.g., API keys)
â”‚
â”œâ”€â”€ frontend/
â”‚ â”œâ”€â”€ public/
â”‚ â”‚ â”œâ”€â”€ index.html # Main HTML file
â”‚ â”‚ â””â”€â”€ favicon.ico
â”‚ â”œâ”€â”€ src/
â”‚ â”‚ â”œâ”€â”€ components/
â”‚ â”‚ â”‚ â”œâ”€â”€ FileUpload.js # Component for document upload
â”‚ â”‚ â”‚ â”œâ”€â”€ SummaryDisplay.js # Displays document summary
â”‚ â”‚ â”‚ â”œâ”€â”€ AskAnything.js # Interface for free-form questions
â”‚ â”‚ â”‚ â”œâ”€â”€ ChallengeMe.js # Interface for challenge mode
â”‚ â”‚ â”‚ â””â”€â”€ HistoryDisplay.js # Displays highlighted document snippets
â”‚ â”‚ â”œâ”€â”€ App.js # Main React app
â”‚ â”‚ â”œâ”€â”€ App.css # Tailwind CSS imports
â”‚ â”‚ â”œâ”€â”€ index.js # React entry point
â”‚ â”‚ â””â”€â”€ axios.js # Axios setup for API calls
â”‚ â”œâ”€â”€ package.json # Node dependencies
â”‚ â””â”€â”€ tailwind.config.js # Tailwind CSS configuration
â”‚
â”œâ”€â”€ README.md # Project documentation
â”œâ”€â”€ .gitignore # Git ignore file

---


## ğŸ“„ Description

- `backend/`: Contains the FastAPI application and logic for document parsing, summarization, question answering, and challenge-based evaluation.
- `frontend/`: React Single Page Application (SPA) with upload interface, summary viewer, Q&A chat, and challenge mode.

---
## ğŸ§° Dependencies Setup

### ğŸ”§ Backend Setup

1. Navigate to the backend directory:
   ```bash
   cd backend
Create and activate a virtual environment:

bash
Copy
Edit
python -m venv venv_name
.\venv_name\Scripts\activate   # On Windows
Install the required dependencies:

bash
Copy
Edit
pip install -r requirements.txt
Create a .env file inside the backend folder and add your Google API key:

ini
Copy
Edit
GOOGLE_API_KEY=your_api_key_here
ğŸŒ Frontend Setup
Navigate to the frontend directory:

bash
Copy
Edit
cd frontend
Install dependencies using npm:

bash
Copy
Edit
npm install
â–¶ï¸ Running the Project
ğŸš€ Start the Backend
bash
Copy
Edit
python -m app.main
This runs the FastAPI backend at http://localhost:8000.

ğŸ’» Start the Frontend
bash
Copy
Edit
npm start
This runs the React frontend at http://localhost:3000 or http://localhost:5000, depending on configuration.

ğŸ¯ Accuracy Feature
In Challenge Me mode, the app presents three logic-based questions based on the uploaded document. Your answers will be evaluated, and justifications will be shown alongside the responseâ€”helping users assess their understanding of the content.

ğŸ¤– Q&A Chatbot
You can ask any question about the uploaded research paper. Just type the question in the input field, and the AI will respond with an answer and a justification. Everything happens in the same interactive chat area.

ğŸ”„ Data Flow Description
The project is divided into two major parts:

Frontend: React-based Single Page Application (SPA)

Backend: FastAPI-based document processor and QA system using Gemini and FAISS

ğŸ“¥ User Interaction (Frontend)
Users visit the app at http://localhost:3000.

App.js starts in upload mode, showing the FileUpload.js component.

Users upload a PDF/TXT file.

ğŸ“¤ File Upload Request (Frontend â†’ Backend)
FileUpload.js sends a POST request to http://localhost:8000/upload with the file using axios.

The backend processes the file and returns:

json
Copy
Edit
{
  "text": "original_document_text",
  "summary": "generated_summary"
}
App.js updates state and switches to summary view.

ğŸ§  Document Processing (Backend)
main.py receives the file via /upload.

document_processor.py extracts text and generates summary.

Summary and document text are stored in memory via ContextManager.

ğŸ“° Summary Display (Frontend)
App.js renders SummaryDisplay.js.

User can switch to:

'ask' â†’ renders AskAnything.js

'challenge' â†’ renders ChallengeMe.js

â“ Question Submission (Frontend â†’ Backend)
AskAnything.js sends a POST request to /ask with:

json
Copy
Edit
{ "question": "your_question_here" }
ğŸ’¡ Question Answering (Backend)
main.py verifies the document is present.

Calls answer_question() from question_answerer.py.

question_answerer.py Details:
Splits document into chunks.

Builds FAISS index with HuggingFaceEmbeddings (all-MiniLM-L6-v2).

Retrieves relevant chunks via similarity search.

Constructs prompt using:

User's question

Retrieved context

Conversation history

Uses Gemini (gemini-1.5-flash) to generate an answer.

Extracts justification from top result.

Stores interaction in ContextManager.

Returns:

json
Copy
Edit
{
  "question": "original_question",
  "answer": "generated_answer",
  "justification": "why_this_answer"
}
ğŸ“¬ Response Display (Frontend)
AskAnything.js updates the response in state.

The question, answer, and justification are rendered.

History is updated via addToHistory().

ğŸ® Challenge Questions (Optional)
ChallengeMe.js sends a GET request to /challenge.

main.py uses generate_challenge_questions() to return a set of logic questions.

User answers are POSTed to /evaluate.

evaluate_answer() processes answers and sends feedback.

ğŸ”Œ External Integrations
Google Gemini API via langchain-google-genai

FAISS for semantic search

HuggingFace embeddings (all-MiniLM-L6-v2) for document chunk vectorization